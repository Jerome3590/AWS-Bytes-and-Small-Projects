---
title: "Urology_Patient_Forecasting_&_Optimization"
author: "Jerome Dixon"
date: "1/20/2022"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(cache = TRUE, warning=FALSE, message=FALSE, eval = FALSE, echo = TRUE)

```


```{r Load-Libraries, results='hide'}

library(readxl)
library(dplyr)
library(magrittr)
library(ggplot2)
library(tidyverse)
library(stringr)
library(here)
library(aws.s3)
library(aws.signature)
library(jsonlite)
library(scales)
```


```{r python-env, results='hide'}

library(reticulate)
py_config()
sagemaker <- import('sagemaker')
session <- sagemaker$Session()
bucket <- session$default_bucket()

role_arn <- session$expand_role('AWSGlueServiceNotebookRole-sagemaker-rstudio')


```


```{r}

data_file <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data'

abalone <- read_csv(file = data_file, col_names = FALSE)

names(abalone) <- c('sex', 'length', 'diameter', 'height', 'whole_weight',
                    'shucked_weight', 'viscera_weight', 'shell_weight', 'rings')

head(abalone)


```


```{r}

abalone$sex <- as.factor(abalone$sex)
summary(abalone)

```


```{r}

library(ggplot2)

ggplot(abalone, aes(x = height, y = rings, color = sex)) + geom_point() + geom_jitter()


```

```{r}

library(dplyr)
abalone <- abalone %>%
  filter(height != 0)

```


```{r}

abalone <- abalone %>%
  mutate(female = as.integer(ifelse(sex == 'F', 1, 0)),
         male = as.integer(ifelse(sex == 'M', 1, 0)),
         infant = as.integer(ifelse(sex == 'I', 1, 0))) %>%
  select(-sex)
abalone <- abalone %>%
  select(rings:infant, length:shell_weight)
head(abalone)


```


```{r}

abalone_train <- abalone %>%
  sample_frac(size = 0.7)
abalone <- anti_join(abalone, abalone_train)
abalone_test <- abalone %>%
  sample_frac(size = 0.5)
abalone_valid <- anti_join(abalone, abalone_test)


```


```{r}

write_csv(abalone_train, 'abalone_train.csv', col_names = FALSE)
write_csv(abalone_valid, 'abalone_valid.csv', col_names = FALSE)

```


```{r}

s3_train <- session$upload_data(path = 'abalone_train.csv', 
                                bucket = bucket, 
                                key_prefix = 'data')
s3_valid <- session$upload_data(path = 'abalone_valid.csv', 
                                bucket = bucket, 
                                key_prefix = 'data')

```


```{r}

s3_train_input <- sagemaker$TrainingInput(s3_data = s3_train,
                                          content_type = 'csv')
s3_valid_input <- sagemaker$TrainingInput(s3_data = s3_valid,
                                          content_type = 'csv')

```


```{r}


container <- sagemaker$image_uris$retrieve(framework = 'xgboost',
                                           region = session$boto_region_name,
                                           version = 'latest')



```


```{r}


s3_output <- paste0('s3://', bucket, '/output')
estimator <- sagemaker$estimator$Estimator(image_uri = container,
                                           role = role_arn,
                                           instance_count = 1L,
                                           instance_type = 'ml.m5.large',
                                           volume_size = 30L,
                                           max_run = 3600L,
                                           input_mode = 'File',
                                           output_path = s3_output,
                                           output_kms_key = NULL,
                                           base_job_name = NULL,
                                           sagemaker_session = session)




```


```{r}


estimator$set_hyperparameters(num_round = 100L)
job_name <- paste('sagemaker-train-xgboost', format(Sys.time(), '%H-%M-%S'), sep = '-')
input_data <- list('train' = s3_train_input,
                   'validation' = s3_valid_input)
estimator$fit(inputs = input_data,
              job_name = job_name)



```


```{r}

estimator$model_data

```


```{r}

model_endpoint <- estimator$deploy(initial_instance_count = 1L,
                                   instance_type = 'ml.t2.medium')

```


```{r}

model_endpoint$serializer <- sagemaker$serializers$CSVSerializer()

```


```{r}

abalone_test <- abalone_test[-1]
num_predict_rows <- 500
test_sample <- as.matrix(abalone_test[1:num_predict_rows, ])
dimnames(test_sample)[[2]] <- NULL


```


```{r}

predictions <- model_endpoint$predict(test_sample)
predictions <- str_split(predictions, pattern = ',', simplify = TRUE)
predictions <- as.numeric(predictions)

```


```{r}

abalone_test <- cbind(predicted_rings = predictions, 
                      abalone_test[1:num_predict_rows, ])
head(abalone_test)    

```


```{r}

model_endpoint$delete_endpoint()


```




















```{sh Update-PGx-Script, include=FALSE}

# Copies Urology Analysis to S3 Code Bucket
aws s3 cp 'Urology-Patient_Forecasting_AND_Optimization.Rmd' s3://pgx-terraform/code/ 

```
    